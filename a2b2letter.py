import re
import csv
import os
import streamlit as st
import pandas as pd
import openai
import stopwordsiso as stop
from datetime import datetime

# === Paths & Constants ===
TRAINING_DATA_PATH   = "essay_training_data.csv"
VOCAB_PATH           = "approved_vocab.csv"
CONNECTOR_PATH       = "approved_connectors.csv"
LOG_PATH             = "submission_log.csv"
STUDENT_CODES_PATH   = "student_codes.csv"

st.set_page_config(page_title="German Letter & Essay Checker", layout="wide")
st.title("üìù German Letter & Essay Checker ‚Äì Learn Language Education Academy")
st.markdown("""
    <style>
    #MainMenu, footer, header, div[data-testid="stHeader"] {visibility: hidden;}
    </style>
""", unsafe_allow_html=True)

# === API KEY ===
api_key = st.secrets.get("general", {}).get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")
if not api_key:
    st.error("‚ùå OpenAI API key not found. Add it to secrets.toml under [general] or set as environment variable.")
    st.stop()
openai.api_key = api_key
client = openai.OpenAI(api_key=api_key)

# === Stopwords & Function Words ===
german_stopwords = stop.stopwords("de")
function_words = {
    w.lower() for w in {
        "ich","du","er","sie","wir","ihr","mir","mich",
        "der","die","das","ein","eine",
        "und","oder","aber","nicht","wie","wann","wo",
        "sein","haben","k√∂nnen","m√ºssen","wollen","sollen",
        "bitte","viel","gut","sehr",
        "wer","was","wann","wo","warum","wie","order"
    }
}

# === Helpers: File/Data ===
def load_student_codes():
    codes = set()
    if os.path.exists(STUDENT_CODES_PATH):
        with open(STUDENT_CODES_PATH, newline='', encoding='utf-8') as f:
            rdr = csv.reader(f)
            headers = next(rdr, [])
            idx = headers.index('student_code') if 'student_code' in headers else 0
            for row in rdr:
                if len(row) > idx and row[idx].strip():
                    codes.add(row[idx].strip())
    return codes

def load_submission_log():
    data = {}
    if os.path.exists(LOG_PATH):
        with open(LOG_PATH, newline='', encoding='utf-8') as f:
            reader = csv.reader(f)
            for row in reader:
                if len(row) < 2:
                    continue
                sid, count = row[0], row[1]
                if sid.lower() == 'student_code':
                    continue
                try:
                    data[sid] = int(count)
                except ValueError:
                    continue
    return data

def save_submission_log(log: dict):
    with open(LOG_PATH, "w", newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        for sid, count in log.items():
            writer.writerow([sid, count])

def save_for_training(student_id, level, task_type, task_num, student_text, gpt_results, feedback_text):
    row = {
        "timestamp": datetime.now().isoformat(timespec="seconds"),
        "student_id": student_id,
        "level": level,
        "task_type": task_type,
        "task_num": task_num,
        "original_text": student_text,
        "gpt_grammar_feedback": "\n".join(gpt_results),
        "full_feedback": feedback_text
    }
    df = pd.DataFrame([row])
    if not os.path.exists(TRAINING_DATA_PATH) or os.stat(TRAINING_DATA_PATH).st_size == 0:
        df.to_csv(TRAINING_DATA_PATH, index=False)
    else:
        df.to_csv(TRAINING_DATA_PATH, mode='a', header=False, index=False)

def load_vocab_from_csv():
    vocab = {"A1": set(), "A2": set()}
    if os.path.exists(VOCAB_PATH):
        with open(VOCAB_PATH, newline='', encoding='utf-8') as f:
            for lvl, word in csv.reader(f):
                if lvl in vocab:
                    vocab[lvl].add(word.strip().lower())
    if not any(vocab.values()):
        vocab["A1"].update(["bitte","danke","tsch√ºss","m√∂chten","schreiben","bezahlen"])
        vocab["A2"].update(["arbeiten","lernen","verstehen","helfen"])
    return vocab

def save_vocab_to_csv(vocab):
    with open(VOCAB_PATH, "w", newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        for lvl in vocab:
            for w in sorted(vocab[lvl]):
                writer.writerow([lvl, w])

def load_connectors_from_csv():
    conns = {l:set() for l in ["A1","A2","B1","B2"]}
    if os.path.exists(CONNECTOR_PATH):
        with open(CONNECTOR_PATH, newline='', encoding="utf-8") as f:
            for lvl, items in csv.reader(f):
                if lvl in conns:
                    conns[lvl].update(i.strip() for i in items.split(",") if i.strip())
    if not any(conns.values()):
        conns = {
            "A1": {"weil","denn","ich m√∂chte wissen","deshalb"},
            "A2": {"deshalb","deswegen","darum","trotzdem","obwohl","sobald",
                   "au√üerdem","zum Beispiel","und","aber","oder","erstens",
                   "zweitens","zum Schluss"},
            "B1": {"jedoch","allerdings","hingegen","dennoch","folglich","daher",
                   "deshalb","damit","sofern","falls","w√§hrenddessen","anschlie√üend",
                   "einerseits","andererseits"},
            "B2": {"allerdings","dennoch","demzufolge","ergo","sodass","obgleich",
                   "ungeachtet","indessen","nichtsdestotrotz","inzwischen",
                   "zusammenfassend","abschlie√üend","letztendlich"}
        }
    return conns

def save_connectors_to_csv(conns):
    with open(CONNECTOR_PATH, "w", newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        for lvl in conns:
            if conns[lvl]:
                writer.writerow([lvl, ", ".join(sorted(conns[lvl]))])

# === Long Phrase Detection ===
def detect_long_phrases(text: str, level: str) -> list[str]:
    thresh = 6 if level == "A1" else 8 if level == "A2" else 1000  # Only for A1/A2
    if level not in ("A1","A2"):
        return []
    tokens = [(m.group(0), m.start(), m.end()) for m in re.finditer(r"\b\w+\b", text)]
    phrases = []
    for i in range(len(tokens) - thresh + 1):
        start_idx = tokens[i][1]
        end_idx   = tokens[i + thresh - 1][2]
        phrase = text[start_idx:end_idx]
        if len(re.findall(r"\b\w+\b", phrase)) >= thresh:
            phrases.append(phrase)
    # Remove overlaps: only highlight longest unique spans
    seen = set()
    unique = []
    for ph in phrases:
        if ph not in seen:
            seen.add(ph)
            unique.append(ph)
    return unique

# === GPT Grammar Check ===
def grammar_check_with_gpt(text: str) -> list[str]:
    prompt = (
        "You are a German language tutor. "
        "Check the following German text for grammar and spelling errors. "
        "For each error, return a line in this format:\n"
        "`<error substring>` ‚áí `<suggestion>` ‚Äî `<brief English explanation>`\n\n"
        f"Text:\n{text}"
    )
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )
    return response.choices[0].message.content.strip().splitlines()

# === Annotate Text (Grammar, Long Phrases) ===
def annotate_text(student_text, gpt_results, long_phrases, level):
    ann = student_text
    colors = {'Grammar':'#e15759','Phrase':'#f1c232'}
    # Highlight grammar errors
    for line in gpt_results or []:
        if "‚áí" in line:
            err = line.split("‚áí")[0].strip(" `")
            pat = rf"(?i)\b{re.escape(err)}\b"
            ann = re.sub(pat,
                         lambda m: f"<span style='background-color:{colors['Grammar']}; color:#fff'>{m.group(0)}</span>",
                         ann)
    # Highlight long phrases for A1/A2
    for phrase in long_phrases:
        pat = re.escape(phrase)
        ann = re.sub(pat,
                     lambda m: f"<span title='Too long for {level}' style='background-color:{colors['Phrase']}; color:#000'>{m.group(0)}</span>",
                     ann)
    return ann.replace("\n", "  \n")

# === Scoring & Feedback ===
def score_text(student_text, level, gpt_results, adv):
    words = re.findall(r"\w+", student_text.lower())
    unique_ratio = len(set(words)) / len(words) if words else 0
    sentences = re.split(r"[.!?]", student_text)
    avg_words = len(words) / max(1, len([s for s in sentences if s.strip()]))
    if avg_words <= 12:
        readability = "Easy"
    elif avg_words <= 17:
        readability = "Medium"
    else:
        readability = "Hard"
    content_score   = 10
    grammar_score   = max(1, 5 - len(gpt_results))
    vocab_score     = min(5, int((len(set(words)) / len(words)) * 5))
    if adv:
        vocab_score = max(1, vocab_score - 1)
    structure_score = 5
    total           = content_score + grammar_score + vocab_score + structure_score
    return (content_score, grammar_score, vocab_score,
            structure_score, total, unique_ratio, avg_words, readability)

def generate_feedback_text(level, task_type, task,
                          content_score, grammar_score, vocab_score,
                          structure_score, total,
                          gpt_results, long_phrases, used_connectors, student_text):
    return f"""Your Feedback ‚Äì {task_type} ({level})
Task: {task['task'] if task else ''}
Scores:
- Content: {content_score}/10
- Grammar: {grammar_score}/5
- Vocabulary: {vocab_score}/5
- Structure: {structure_score}/5
Total: {total}/25

Grammar Suggestions:
{chr(10).join(gpt_results) if gpt_results else 'No major grammar errors detected.'}

Long Phrases (flagged as too long):
{', '.join(long_phrases) if long_phrases else 'None'}

Connectors Used:
{', '.join(used_connectors) if used_connectors else 'None'}

Your Text:
{student_text}
"""

# === A1 Schreiben Tasks ===
a1_tasks = {
    1: {"task": "Schreiben Sie eine E-Mail an Ihren Arzt und sagen Sie Ihren Termin ab.",
        "points": ["Warum schreiben Sie?", "Sagen Sie: den Grund f√ºr die Absage.", "Fragen Sie: nach einem neuen Termin."]},
    2: {"task": "Schreiben Sie eine Einladung an Ihren Freund zur Feier Ihres neuen Jobs.",
        "points": ["Warum schreiben Sie?", "Wann ist die Feier?", "Wer soll was mitbringen?"]},
    3: {"task": "Schreiben Sie eine E-Mail an einen Freund und teilen Sie ihm mit, dass Sie ihn besuchen m√∂chten.",
        "points": ["Warum schreiben Sie?", "Wann besuchen Sie ihn?", "Was m√∂chten Sie zusammen machen?"]},
    4: {"task": "Schreiben Sie eine E-Mail an Ihre Schule und fragen Sie nach einem Deutschkurs.",
        "points": ["Warum schreiben Sie?", "Was m√∂chten Sie wissen?", "Wie kann die Schule antworten?"]},
    5: {"task": "Schreiben Sie eine E-Mail an Ihre Vermieterin. Ihre Heizung ist kaputt.",
        "points": ["Warum schreiben Sie?", "Seit wann ist die Heizung kaputt?", "Was soll die Vermieterin tun?"]},
    6: {"task": "Schreiben Sie eine E-Mail an Ihren Freund. Sie haben eine neue Wohnung.",
        "points": ["Warum schreiben Sie?", "Wo ist die Wohnung?", "Was gef√§llt Ihnen?"]},
    7: {"task": "Schreiben Sie eine E-Mail an Ihre Freundin. Sie haben eine neue Arbeitsstelle.",
        "points": ["Warum schreiben Sie?", "Wo arbeiten Sie jetzt?", "Was machen Sie?"]},
    8: {"task": "Schreiben Sie eine E-Mail an Ihren Lehrer. Sie k√∂nnen am Kurs nicht teilnehmen.",
        "points": ["Warum schreiben Sie?", "Warum kommen Sie nicht?", "Was m√∂chten Sie?"]},
    9: {"task": "Schreiben Sie eine E-Mail an die Bibliothek. Sie haben ein Buch verloren.",
        "points": ["Warum schreiben Sie?", "Welches Buch haben Sie verloren?", "Was m√∂chten Sie wissen?"]},
    10: {"task": "Schreiben Sie eine E-Mail an Ihre Freundin. Sie m√∂chten mit ihr in den Urlaub fahren.",
         "points": ["Warum schreiben Sie?", "Wohin m√∂chten Sie fahren?", "Was m√∂chten Sie dort machen?"]},
    11: {"task": "Schreiben Sie eine E-Mail an Ihre Schule. Sie m√∂chten einen Termin √§ndern.",
         "points": ["Warum schreiben Sie?", "Welcher Termin ist es?", "Wann haben Sie Zeit?"]},
    12: {"task": "Schreiben Sie eine E-Mail an Ihren Bruder. Sie machen eine Party.",
         "points": ["Warum schreiben Sie?", "Wann ist die Party?", "Was soll Ihr Bruder mitbringen?"]},
    13: {"task": "Schreiben Sie eine E-Mail an Ihre Freundin. Sie sind krank.",
         "points": ["Warum schreiben Sie?", "Was machen Sie heute nicht?", "Was sollen Sie tun?"]},
    14: {"task": "Schreiben Sie eine E-Mail an Ihre Nachbarn. Sie machen Urlaub.",
         "points": ["Warum schreiben Sie?", "Wie lange sind Sie weg?", "Was sollen die Nachbarn tun?"]},
    15: {"task": "Schreiben Sie eine E-Mail an Ihre Deutschlehrerin. Sie m√∂chten eine Pr√ºfung machen.",
         "points": ["Warum schreiben Sie?", "Welche Pr√ºfung m√∂chten Sie machen?", "Wann m√∂chten Sie die Pr√ºfung machen?"]},
    16: {"task": "Schreiben Sie eine E-Mail an Ihre Freundin. Sie haben einen neuen Computer gekauft.",
         "points": ["Warum schreiben Sie?", "Wo haben Sie den Computer gekauft?", "Was gef√§llt Ihnen besonders?"]},
    17: {"task": "Schreiben Sie eine E-Mail an Ihre Freundin. Sie m√∂chten zusammen Sport machen.",
         "points": ["Warum schreiben Sie?", "Welchen Sport m√∂chten Sie machen?", "Wann k√∂nnen Sie?"]},
    18: {"task": "Schreiben Sie eine E-Mail an Ihren Freund. Sie brauchen Hilfe beim Umzug.",
         "points": ["Warum schreiben Sie?", "Wann ist der Umzug?", "Was soll Ihr Freund machen?"]},
    19: {"task": "Schreiben Sie eine E-Mail an Ihre Freundin. Sie m√∂chten ein Fest organisieren.",
         "points": ["Warum schreiben Sie?", "Wo soll das Fest sein?", "Was m√∂chten Sie machen?"]},
    20: {"task": "Schreiben Sie eine E-Mail an Ihre Freundin. Sie m√∂chten zusammen kochen.",
         "points": ["Warum schreiben Sie?", "Was m√∂chten Sie kochen?", "Wann m√∂chten Sie kochen?"]},
    21: {"task": "Schreiben Sie eine E-Mail an Ihren Freund. Sie haben einen neuen Job.",
         "points": ["Warum schreiben Sie?", "Wo arbeiten Sie jetzt?", "Was machen Sie?"]},
    22: {"task": "Schreiben Sie eine E-Mail an Ihre Schule. Sie m√∂chten einen Deutschkurs besuchen.",
         "points": ["Warum schreiben Sie?", "Wann m√∂chten Sie den Kurs besuchen?", "Was m√∂chten Sie noch wissen?"]}
}

# --- Teacher Settings ---
st.sidebar.header("üîß Teacher Settings")
teacher_password = st.sidebar.text_input("üîí Enter teacher password", type="password")
teacher_mode = (teacher_password == "Felix029")
if teacher_mode:
    page = st.sidebar.radio("Go to:", ["Student View", "Teacher Dashboard"])
else:
    page = "Student View"

# Utility to download training data
def download_training_data():
    if os.path.exists(TRAINING_DATA_PATH) and os.stat(TRAINING_DATA_PATH).st_size > 0:
        with open(TRAINING_DATA_PATH, 'rb') as f:
            st.download_button(
                "‚¨áÔ∏è Download All Submissions",
                data=f,
                file_name="essay_training_data.csv",
                mime="text/csv"
            )
    else:
        st.info("No training data collected yet.")

# Teacher Dashboard
if teacher_mode and page == "Teacher Dashboard":
    st.header("üìã Teacher Dashboard")

    with st.expander("üìù Edit Approved Vocabulary (A1/A2)"):
        vocab = load_vocab_from_csv()
        for lvl in ["A1", "A2"]:
            current = ", ".join(sorted(vocab.get(lvl, set())))
            new_vocab = st.text_area(f"{lvl} Vocabulary (comma-separated):", current, key=f"vocab_{lvl}")
            if st.button(f"Update {lvl} Vocab", key=f"btn_vocab_{lvl}"):
                words = {w.strip().lower() for w in new_vocab.split(",") if w.strip()}
                vocab[lvl] = words
                save_vocab_to_csv(vocab)
                st.success(f"‚úÖ {lvl} vocabulary updated.")

    with st.expander("üîó Edit Approved Connectors (A1‚ÄìB2)"):
        connectors = load_connectors_from_csv()
        for lvl in ["A1", "A2", "B1", "B2"]:
            current = ", ".join(sorted(connectors.get(lvl, set())))
            new_conns = st.text_area(f"{lvl} Connectors (comma-separated):", current, key=f"conn_{lvl}")
            if st.button(f"Update {lvl} Connectors", key=f"btn_conn_{lvl}"):
                items = {c.strip() for c in new_conns.split(",") if c.strip()}
                connectors[lvl] = items
                save_connectors_to_csv(connectors)
                st.success(f"‚úÖ {lvl} connectors updated.")

    with st.expander("üë©‚Äçüéì Student Codes"):
        student_codes = load_student_codes()
        st.write(sorted(student_codes))
        new_codes = st.text_area("Add student codes (comma-separated):")
        if st.button("Add to Student Codes"):
            for code in [s.strip() for s in new_codes.split(',') if s.strip()]:
                student_codes.add(code)
            with open(STUDENT_CODES_PATH, "w", encoding="utf-8", newline="") as f:
                writer = csv.writer(f)
                writer.writerow(["student_code"])
                for c in sorted(student_codes):
                    writer.writerow([c])
            st.success("‚úÖ Student codes updated.")

    with st.expander("üìà Submission Log"):
        df_log = pd.DataFrame(load_submission_log().items(), columns=["student_code","count"])
        st.dataframe(df_log)
        st.download_button(
            "üíæ Download submission_log.csv",
            data=df_log.to_csv(index=False).encode('utf-8'),
            file_name="submission_log.csv",
            mime="text/csv"
        )
        uploaded = st.file_uploader(
            "üîÑ Upload previous submission_log.csv to restore counts",
            type="csv",
            help="After deploying new code, re-import your last export here."
        )
        if uploaded:
            with open(LOG_PATH, "wb") as f:
                f.write(uploaded.getbuffer())
            st.success("‚úÖ Submission log restored. Reload the page to see updated counts.")

    with st.expander("üìä Collected Essays for AI Training"):
        download_training_data()

    st.stop()

# --- Student Interface & Feedback ---
approved_vocab      = load_vocab_from_csv()
student_codes       = load_student_codes()
log_data            = load_submission_log()
connectors_by_level = load_connectors_from_csv()

level = st.selectbox("Select your level", ["A1","A2","B1","B2"])
tasks = ["Formal Letter","Informal Letter"]
if level in ("B1","B2"):
    tasks.append("Opinion Essay")
task_type = st.selectbox("Select task type", tasks)

student_id = st.text_input("Enter your student code:")
if not student_id:
    st.warning("Please enter your student code.")
    st.stop()
if student_id not in student_codes:
    st.error("‚ùå You are not authorized to use this app.")
    st.stop()

subs     = log_data.get(student_id, 0)
max_subs = 40 if level == "A1" else 45
if subs >= max_subs:
    st.warning(f"‚ö†Ô∏è You have reached the maximum of {max_subs} submissions.")
    st.stop()
if subs >= max_subs - 12:
    st.info("‚è≥ You have used most of your submission chances. Review carefully!")

# A1-specific task selection
if level == "A1":
    task_num = st.number_input(
        f"Choose a Schreiben task number (1‚Äì{len(a1_tasks)})",
        1, len(a1_tasks), 1
    )
    task = a1_tasks.get(task_num)
    st.markdown(f"### Aufgabe {task_num}: {task['task']}")
    st.markdown("**Points:**")
    for p in task["points"]:
        st.markdown(f"- {p}")
else:
    task_num = None
    task = None

student_text = st.text_area("‚úèÔ∏è Write your letter or essay below:", height=300)

if st.button("‚úÖ Submit for Feedback"):
    with st.spinner("üîÑ Processing your submission‚Ä¶"):
        if not student_text.strip():
            st.warning("Please enter your text before submitting.")
            st.stop()

        # 1. Grammar check
        gpt_results = grammar_check_with_gpt(student_text)

        # 2. Long phrase/advanced vocab detection
        adv = detect_long_phrases(student_text, level)

        # 3. Connectors used
        used_connectors = [
            c for c in connectors_by_level.get(level, [])
            if c.lower() in student_text.lower()
        ]

        # 4. Score calculation
        (content_score, grammar_score, vocab_score,
         structure_score, total, unique_ratio, avg_words,
         readability) = score_text(student_text, level, gpt_results, adv)

        # 5. Generate feedback text
        feedback_text = generate_feedback_text(
            level, task_type, task, content_score, grammar_score,
            vocab_score, structure_score, total,
            gpt_results, adv, used_connectors, student_text
        )

        # 6. Save for training and update log
        save_for_training(
            student_id=student_id,
            level=level,
            task_type=task_type,
            task_num=task_num,
            student_text=student_text,
            gpt_results=gpt_results,
            feedback_text=feedback_text
        )
        log_data[student_id] = subs + 1
        save_submission_log(log_data)

    # Display metrics
    st.markdown(f"üßÆ Readability: {readability} ({avg_words:.1f} w/s)")
    st.metric("Content",    f"{content_score}/10")
    st.metric("Grammar",    f"{grammar_score}/5")
    st.metric("Vocabulary", f"{vocab_score}/5")
    st.metric("Structure",  f"{structure_score}/5")
    st.markdown(f"**Total: {total}/25**")

    # Why these scores
    st.markdown("**Why these scores?**")
    st.markdown(f"- üìñ Content: fixed = {content_score}/10")
    st.markdown(f"- ‚úèÔ∏è Grammar: {len(gpt_results)} errors ‚áí {grammar_score}/5")
    st.markdown(f"- üí¨ Vocabulary: unique ratio {unique_ratio:.2f} ‚áí {vocab_score}/5")
    st.markdown(f"- üîß Structure: fixed = {structure_score}/5")

    # Grammar suggestions
    if gpt_results:
        st.markdown("**Grammar Suggestions:**")
        for i, line in enumerate(gpt_results, 1):
            st.markdown(f"{i}. {line}")

    # Connector hints
    hints = sorted(connectors_by_level.get(level, []))[:4]
    st.info(f"üìù Try connectors like: {', '.join(hints)}‚Ä¶")

    # Annotated text
    ann = annotate_text(student_text, gpt_results, adv, connectors_by_level, level)
    st.markdown("**Annotated Text:**", unsafe_allow_html=True)
    st.markdown(ann, unsafe_allow_html=True)

    # Highlight explanations
    st.markdown("### üîç What was highlighted and why")
    if gpt_results:
        st.markdown("- üî¥ Grammar errors: " + ", ".join(e.split("‚áí")[0].strip(" `") for e in gpt_results))
    if adv:
        st.markdown("- üü° Too-long phrase(s): " + ", ".join(adv))
    if used_connectors:
        st.markdown("- üü¢ Connectors used: " + ", ".join(used_connectors))

    # Passive voice
    passives = re.findall(r"\b(?:wird\s+\w+\s+von|ist\s+\w+\s+worden)\b", student_text, flags=re.I)
    if passives:
        st.markdown("- üü† Passive voice flagged: " + ", ".join(passives))

    # Long sentences
    long_sents = re.findall(r"([A-Z√Ñ√ñ√ú][^\.!?]{100,}[\.!?])", student_text)
    if long_sents:
        st.markdown("- ‚ö™Ô∏è Long sentence(s): " + " | ".join(long_sents[:3]) + (" ..." if len(long_sents)>3 else ""))

    # Noun capitalization issues
    noun_issues = re.findall(r"\b(?:der|die|das|ein|eine|mein|dein)\s+([a-z√§√∂√º√ü]+)\b", student_text, flags=re.I)
    if noun_issues:
        st.markdown("- üü† Noun capitalization missing: " + ", ".join(noun_issues))

    # Punctuation issues
    ds = re.findall(r" {2,}", student_text)
    mc = re.findall(r",(?=[A-Za-z√ñ√ú√Ñ])", student_text)
    if ds or mc:
        issues = []
        if ds: issues.append(f"{len(ds)} double space(s)")
        if mc: issues.append(f"{len(mc)} comma-space issue(s)")
        st.markdown("- üî¥ Punctuation issues: " + "; ".join(issues))

    # Repeated words
    repeats = re.findall(r"\b(\w+)\s+\1\b", student_text, flags=re.I)
    if repeats:
        st.markdown("- üî¥ Repeated words: " + ", ".join(sorted(set(repeats))))

    # Download feedback
    st.download_button(
        "üíæ Download feedback", data=feedback_text,
        file_name="feedback.txt"
    )
